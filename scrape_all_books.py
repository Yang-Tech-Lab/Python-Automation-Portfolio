import requests
import pandas as pd
from bs4 import BeautifulSoup
import time # å¼•å…¥æ—¶é—´åº“ï¼Œç”¨æ¥æ¨¡æ‹Ÿä¼‘æ¯

print("ğŸš€ å¯åŠ¨è¶…çº§çˆ¬è™«ï¼å‡†å¤‡æŠ“å–å‰ 5 é¡µçš„æ•°æ®...")

# åˆ›å»ºä¸€ä¸ªå¤§åˆ—è¡¨ï¼Œç”¨æ¥è£…æ‰€æœ‰é¡µé¢çš„ä¹¦
all_books_data = []

# å¾ªç¯ 1 åˆ° 5 é¡µ (range(1, 6) æ„æ€æ˜¯ä»1å¼€å§‹ï¼Œåˆ°6ç»“æŸï¼Œä¸åŒ…å«6)
# å¦‚æœä½ æƒ³æŠ“ 50 é¡µï¼Œå°±æŠŠ 6 æ”¹æˆ 51
for page_num in range(1, 6):
    print(f"æ­£åœ¨æŠ“å–ç¬¬ {page_num} é¡µ...")
    
    # æ„é€ æ¯ä¸€é¡µçš„ç½‘å€ (æ³¨æ„ f-string çš„ç”¨æ³•)
    url = f"http://books.toscrape.com/catalogue/page-{page_num}.html"
    
    # å‘é€è¯·æ±‚
    response = requests.get(url)
    
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        books_on_page = soup.find_all("article", class_="product_pod")
        
        # éå†è¿™ä¸€é¡µçš„æ¯ä¸€æœ¬ä¹¦
        for book in books_on_page:
            title = book.h3.a["title"]
            price = book.find("p", class_="price_color").text.replace('Ã‚', '')
            
            # å­˜å…¥å¤§åˆ—è¡¨
            all_books_data.append({
                'é¡µç ': page_num,  # è®°å½•ä¸€ä¸‹æ˜¯å“ªä¸€é¡µæŠ“çš„
                'ä¹¦å': title,
                'ä»·æ ¼': price
            })
    else:
        print(f"âš ï¸ ç¬¬ {page_num} é¡µè¿æ¥å¤±è´¥ï¼")
    
    # ã€é˜²å°å·å…³é”®ã€‘æ¯æŠ“å®Œä¸€é¡µï¼Œä¼‘æ¯ 1 ç§’
    # å‘Šè¯‰ç½‘ç«™ï¼šæˆ‘æ˜¯äººï¼Œæˆ‘ä¸æ˜¯æœºå™¨ï¼Œæˆ‘æ‰‹é€Ÿæ²¡é‚£ä¹ˆå¿«
    time.sleep(1)

print("-" * 30)
print(f"âœ… æŠ“å–ç»“æŸï¼æ€»å…±æŠ“åˆ°äº† {len(all_books_data)} æœ¬ä¹¦ã€‚")
print("æ­£åœ¨ä¿å­˜åˆ° Excel...")

# ä¿å­˜æ–‡ä»¶
df = pd.DataFrame(all_books_data)
df.to_excel('fiverr_books_all.xlsx', index=False)

print("ğŸ‰ æ–‡ä»¶ [fiverr_books_all.xlsx] å·²ç”Ÿæˆï¼")